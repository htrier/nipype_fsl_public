{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This script uses nipype to run a first level analysis using custom three-column regressor files.\n",
    "\n",
    "To use this script, first create custom regressor txt files with [onset, duration, value] information. N.B. Txt files that are read into this script must include the string \".run001\" in their names, as per nipype specifications (see https://nipype.readthedocs.io/en/0.13.1/users/model_specification.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole --style vim #opens a console\n",
    "import nipype.algorithms.modelgen as model  \n",
    "import nipype.pipeline.engine as pe  \n",
    "import nipype.interfaces.fsl as fsl  \n",
    "import glob\n",
    "import os\n",
    "from multiprocessing import Pool #to run FEAT in parallel\n",
    "import shutil #for copying directories\n",
    "\n",
    "# Set path to file containing all subject folders with 3-column regressor txt files \n",
    "data_path = '/Users/haileytrier/Desktop/DPhil_2018/foraging-under-threat/fMRI/Regressor_designs/'\n",
    "os.chdir(data_path)\n",
    "subj_folders = glob.glob('subj*') # each file has subject data for 1 participant\n",
    "nCores = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create design for first-level analysis\n",
    "# dsgn = 3 #indicate for which design to create the fsf files\n",
    "for subj in sorted(subj_folders): #iterate through all participants\n",
    "    for dsgn in range(0,len(glob.glob(data_path+subj+'/' + 'design*'))): #iterate through designs\n",
    "        designpath = data_path+subj+\"/design\"+str(dsgn)\n",
    "        os.chdir(designpath)\n",
    "        file_names = sorted(glob.glob(designpath + '/*.txt')) #get file names where subject info is stored\n",
    "        event_files = [file_names] #see https://github.com/scanlab-admin/nipype/blob/master/dotpro_singlesubject_4_16_12.py\n",
    "        func_scan = '/Users/haileytrier/Desktop/Prolific_output/13Aug2019_Expt_Data/processed_data/epiRun.nii'\n",
    "        # confound_file = '/Users/jscholl/Documents/Dysphoria_study_local/'+subj+'/melodic_func/melodic_func.ica/mc/prefiltered_func_data_mcf.par' if computer=='JS' else \"/Volumes/MyPassport/MDD_ForHailey/data/\"+subj+\"/melodic_func/melodic_func.ica/mc/prefiltered_func_data_mcf.par\"\n",
    "        TR=1.9\n",
    "        TR_name = \"1-9\"\n",
    "\n",
    "        # https://nipype.readthedocs.io/en/latest/users/examples/fmri_fsl.html#set-up-model-fitting-workflow\n",
    "        ### 1. Setup package-specific configuration. The output file format for FSL routines is being set to compressed NIFTI\n",
    "        fsl.FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "        ### 2. Set up a new workflow\n",
    "        modelfit = pe.Workflow(name='level1analysis_TR'+TR_name)\n",
    "        modelfit.base_dir = designpath#os.path.abspath('./level1design/') #where the .fsf and other output will be saved\n",
    "        modelfit.config = {\n",
    "            \"execution\": {\n",
    "                \"crashdump_dir\": os.path.abspath('./fsl/crashdumps')\n",
    "            }\n",
    "        }\n",
    "\n",
    "        ### 3. Specify the contrasts\n",
    "        # Format: cont = ['Name_of_contrast', test ('T' or 'F'), ['name_of_regressor1','name_of_regressor2'], [value of each regressor in this contrast]]\n",
    "        # 1. Contrasts - vigilance period\n",
    "        cont1 = ['v_firstChecks_constant', 'T', ['vigilance_firstChecks_constant'], [1]]\n",
    "        cont2 = ['v_firstForages_constant', 'T', ['vigilance_firstForages_constant'], [1]]\n",
    "        cont3 = ['v_checkForage_constant_diff', 'T', ['vigilance_firstChecks_constant', \n",
    "                                                      'vigilance_firstForages_constant'], [1, -1]]\n",
    "        cont4 = ['v_firstChecks_pPredator','T',['vigilance_firstChecks_pPredator'],[1]]\n",
    "        cont5 = ['v_firstForages_pPredator','T',['vigilance_firstForages_pPredator'],[1]]\n",
    "        cont6 = ['v_checkForage_pPredator_diff','T',['vigilance_firstChecks_pPredator',\n",
    "                                                     'vigilance_firstForages_pPredator'],[1, -1]]\n",
    "        cont7 = ['v_firstChecks_reward','T',['vigilance_firstChecks_reward'],[1]]\n",
    "        cont8 = ['v_firstForages_reward','T',['vigilance_firstForages_reward'],[1]]\n",
    "        cont9 = ['v_checkForage_reward_diff','T',['vigilance_firstChecks_reward',\n",
    "                                                  'vigilance_firstForages_reward'],[1, -1]]\n",
    "        cont10 = ['v_firstChecks_time','T',['vigilance_firstChecks_timePressure'],[1]]\n",
    "        cont11 = ['v_firstForages_time','T',['vigilance_firstForages_timePressure'],[1]]\n",
    "        cont12 = ['v_checkForage_time_diff','T',['vigilance_firstChecks_timePressure',\n",
    "                                                 'vigilance_firstForages_timePressure'],[1, -1]]\n",
    "        cont13 = ['m_checks_constant','T',['monitoring_allChecks_constant'],[1]]\n",
    "        cont14 = ['vm_check_constant_diff','T',['vigilance_firstChecks_constant',\n",
    "                                                    'monitoring_allChecks_constant'],[1, -1]]\n",
    "        cont18 = ['m_checks_posU','T',['monitoring_allChecks_posUncertainty'],[1]]\n",
    "        cont21 = ['m_checks_proximity','T',['monitoring_allChecks_proximity'],[1]]\n",
    "        cont24 = ['m_checks_reward','T',['monitoring_allChecks_reward'],[1]]\n",
    "        if dsgn in [0,2,3,4]:\n",
    "            cont15 = ['m_firstForage_constant','T',['monitoring_firstForages_constant'],[1]]\n",
    "            cont16 = ['vm_firstForages_diff','T',['vigilance_firstForages_constant',\n",
    "                                                  'monitoring_firstForages_constant'],[1, -1]]\n",
    "            cont17 = ['m_checkForage_diff','T',['monitoring_allChecks_constant',\n",
    "                                                'monitoring_firstForages_constant'],[1, -1]]\n",
    "            cont19 = ['m_firstForages_posU','T',['monitoring_firstForages_posUncertainty'],[1]]\n",
    "            cont20 = ['m_checkForage_posU_diff','T',['monitoring_allChecks_posUncertainty',\n",
    "                                                    'monitoring_firstForages_posUncertainty'],[1, -1]]\n",
    "            cont22 = ['m_firstForages_proximity','T',['monitoring_firstForages_proximity'],[1]]\n",
    "            cont23 = ['m_checkForage_proximity_diff','T',['monitoring_allChecks_proximity',\n",
    "                                                         'monitoring_firstForages_proximity'],[1, -1]]\n",
    "            cont25 = ['m_firstForages_reward','T',['monitoring_firstForages_reward'],[1]]\n",
    "            cont26 = ['m_checkForage_reward_diff','T',['monitoring_allChecks_reward',\n",
    "                                                       'monitoring_firstForages_reward'],[1, -1]]\n",
    "            contrasts = [cont1,cont2,cont3,cont4,cont5,cont6,cont7,cont8,cont9,cont10,cont11,cont12,cont13,cont14,\n",
    "                        cont15,cont16,cont17,cont18,cont19,cont20,cont21,cont22,cont23,cont24,cont25,cont26]\n",
    "        elif dsgn==5:\n",
    "            cont15 = ['m_allForage_constant','T',['monitoring_allForages_constant'],[1]]\n",
    "            cont16 = ['vm_forages_diff','T',['vigilance_firstForages_constant',\n",
    "                                                  'monitoring_allForages_constant'],[1, -1]]\n",
    "            cont17 = ['m_checkForage_diff','T',['monitoring_allChecks_constant',\n",
    "                                                'monitoring_allForages_constant'],[1, -1]]\n",
    "            cont19 = ['m_firstForages_posU','T',['monitoring_allForages_posUncertainty'],[1]]\n",
    "            cont20 = ['m_checkForage_posU_diff','T',['monitoring_allChecks_posUncertainty',\n",
    "                                                    'monitoring_allForages_posUncertainty'],[1, -1]]\n",
    "            cont22 = ['m_allForages_proximity','T',['monitoring_allForages_proximity'],[1]]\n",
    "            cont23 = ['m_checkForage_proximity_diff','T',['monitoring_allChecks_proximity',\n",
    "                                                         'monitoring_allForages_proximity'],[1, -1]]\n",
    "            cont25 = ['m_allForages_reward','T',['monitoring_allForages_reward'],[1]]\n",
    "            cont26 = ['m_checkForage_reward_diff','T',['monitoring_allChecks_reward',\n",
    "                                                       'monitoring_allForages_reward'],[1, -1]]\n",
    "            cont27 = ['m_checkForage_sum','T',['monitoring_allForages_constant',\n",
    "                                                       'monitoring_allChecks_constant'],[1,1]]\n",
    "            cont28 = ['m_checkForage_reward_sum','T',['monitoring_allChecks_reward',\n",
    "                                                       'monitoring_allForages_reward'],[1,1]]\n",
    "            cont29 = ['m_checkForage_posU_sum','T',['monitoring_allChecks_posUncertainty',\n",
    "                                                    'monitoring_allForages_posUncertainty'],[1,1]]\n",
    "            cont30 = ['m_checkForage_proximity_sum','T',['monitoring_allChecks_proximity',\n",
    "                              'monitoring_allForages_proximity'],[1,1]]\n",
    "            contrasts = [cont1,cont2,cont3,cont4,cont5,cont6,cont7,cont8,cont9,cont10,cont11,cont12,cont13,cont14,\n",
    "                        cont15,cont16,cont17,cont18,cont19,cont20,cont21,cont22,cont23,cont24,cont25,cont26,cont27,\n",
    "                        cont28,cont29,cont30]\n",
    "\n",
    "            \n",
    "        ### 4. Input design information. SpecifyModel() will aggregate this info to create the 'session_info' structure required to run level1design\n",
    "        modelspec = pe.Node(interface=model.SpecifyModel(), name=\"modelspec\",output_names=\"session_info\") \n",
    "        modelspec.inputs.input_units = 'secs'\n",
    "        modelspec.inputs.functional_runs = func_scan\n",
    "        modelspec.inputs.high_pass_filter_cutoff = 100 \n",
    "        modelspec.inputs.time_repetition = TR  \n",
    "        modelspec.inputs.event_files = event_files \n",
    "\n",
    "        # Add as separate realignment parameters (nipype built-in method):\n",
    "        # modelspec.inputs.realignment_parameters=confound_file \n",
    "\n",
    "        mdl = modelspec.run()\n",
    "\n",
    "        ### 5. Generate the fsf file\n",
    "        level1design = pe.Node(interface=fsl.Level1Design(),name=\"level1design\",input_names='session_info',output_names=\"fsf_file\")\n",
    "        level1design.inputs.interscan_interval = TR  #set to the same as time_repetition according to example at https://gist.github.com/daeh/1f04a98c91e1a30d455379dc5983031c\n",
    "        level1design.inputs.bases = {'dgamma': {'derivs': True}}  \n",
    "        level1design.inputs.contrasts = contrasts\n",
    "        level1design.inputs.model_serial_correlations = bool(True)# (True = turn on prewhitening) Option to model serial correlations using an autoregressive estimator (order 1)\n",
    "\n",
    "        # level1design.inputs.session_info=mdl.outputs.session_info #if you want to inspect session_info and then manually enter it\n",
    "        # lvl = level1design.run()\n",
    "\n",
    "        ### 7. Combine nodes into complete workflow\n",
    "        modelfit.connect([\n",
    "            (modelspec, level1design, [('session_info', 'session_info')]),\n",
    "        ])\n",
    "\n",
    "        ### 8. Execute\n",
    "        os.chdir(designpath)#data_path)\n",
    "        mdl = modelfit.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: ERASE LEVEL1DESIGN FOLDERS FROM ABOVE TO RE-COMPUTE\n",
    "for subj in sorted(subj_folders):\n",
    "        shutil.rmtree('/Users/haileytrier/dysphoria-project/Data/Preprocessed/Regressor_txt_files/'+subj+'/design4/level1design',ignore_errors=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Remove previous feat directories if needed to make sure we have a fresh copy\n",
    "for subj in sorted(subj_folders):\n",
    "        shutil.rmtree('/Users/jscholl/Documents/Dysphoria_study_local/'+subj+'/FEAT_design1',ignore_errors=True)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run lower-level feat\n",
    "dsgn=5 #specify for which design feat will be run\n",
    "subj_to_run_FEAT = sorted(subj_folders)#[\"s227\"]\n",
    "def runFeat(subj):\n",
    "    FEAT_design5 = pe.Node(interface=fsl.FEAT(), name=\"FEAT_design5\", output_names=\"session_info\")\n",
    "    FEAT_design5.inputs.fsf_file = data_path+subj+'/design'+str(dsgn)+'/level1design/modelfit/level1design/run0.fsf'\n",
    "    FEAT_design5.base_dir = '/Users/jscholl/Documents/Dysphoria_study_local/'+subj if computer==\"JS\" else '/Volumes/MyPassport/MDD_ForHailey/data/'+subj#os.path.abspath('./FEAT/') #create a new file in the current path for containing the feat output\n",
    "    FEAT_design5.run()\n",
    " \n",
    "    \n",
    "with Pool(nCores) as p:\n",
    "        p.map(runFeat, subj_to_run_FEAT) #https://docs.python.org/3.4/library/multiprocessing.html?highlight=process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before doing higher-level analyses, it's necessary to copy the registration files from the melodic output into the feat output folder\n",
    "for subj in sorted(subj_folders):\n",
    "        shutil.copytree(src='/Volumes/MyPassport/MDD_ForHailey/data/'+subj+'/melodic_func/melodic_func.ica/reg',\\\n",
    "                        dst='/Volumes/MyPassport/MDD_ForHailey/data/'+subj+'/FEAT_design5/run0.feat/reg')  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
